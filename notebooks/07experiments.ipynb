{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 07: Running Experiments\n",
                "\n",
                "This notebook demonstrates how to run the three main experiments from the paper:\n",
                "1. Ablation Study\n",
                "2. Multi-Dataset Benchmarking\n",
                "3. Regulatory Compliance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import subprocess\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Change to project root directory\n",
                "os.chdir(os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'notebooks' else os.getcwd())\n",
                "print(f\"Working directory: {os.getcwd()}\")\n",
                "print(f\"Python executable: {sys.executable}\")\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment(script_path, args):\n",
                "    \"\"\"Run an experiment script using the current Python interpreter.\"\"\"\n",
                "    cmd = [sys.executable, script_path] + args\n",
                "    print(f\"Running: {' '.join(cmd)}\")\n",
                "    print(\"-\" * 60)\n",
                "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
                "    print(result.stdout)\n",
                "    if result.stderr:\n",
                "        print(\"STDERR:\", result.stderr)\n",
                "    if result.returncode != 0:\n",
                "        print(f\"WARNING: Command exited with code {result.returncode}\")\n",
                "    return result.returncode == 0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 1: Ablation Study\n",
                "\n",
                "Test the impact of removing key FAIR-CARE components."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run experiment (this may take ~30 minutes)\n",
                "run_experiment(\n",
                "    'experiments/scripts/runexperiment1.py',\n",
                "    [\n",
                "        '--datasets', 'compas',\n",
                "        '--configs', 'baseline,configa,configb,configc,default',\n",
                "        '--output', 'results/exp1.csv'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and visualize results\n",
                "exp1 = pd.read_csv('results/exp1.csv')\n",
                "exp1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot FAIR-CARE scores by configuration\n",
                "plt.figure(figsize=(10, 6))\n",
                "exp1.groupby('config')['faircarescore'].mean().sort_values().plot(kind='barh', color='steelblue')\n",
                "plt.xlabel('FAIR-CARE Score')\n",
                "plt.ylabel('Configuration')\n",
                "plt.title('Ablation Study: FAIR-CARE Score by Configuration')\n",
                "plt.axvline(x=0.85, color='green', linestyle='--', label='EXCELLENT')\n",
                "plt.axvline(x=0.70, color='orange', linestyle='--', label='ACCEPTABLE')\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 2: Multi-Dataset Benchmarking\n",
                "\n",
                "Compare FAIR-CARE performance across datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run experiment (this may take ~45 minutes)\n",
                "run_experiment(\n",
                "    'experiments/scripts/runexperiment2.py',\n",
                "    [\n",
                "        '--datasets', 'compas,adult,german',\n",
                "        '--config', 'experiments/configs/default.yaml',\n",
                "        '--output', 'results/exp2.csv'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and visualize results\n",
                "exp2 = pd.read_csv('results/exp2.csv')\n",
                "exp2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot layer scores by dataset\n",
                "grouped = exp2.groupby('dataset')[['SB', 'SS', 'SG', 'faircarescore']].mean()\n",
                "\n",
                "grouped.plot(kind='bar', figsize=(12, 6))\n",
                "plt.ylabel('Score')\n",
                "plt.xlabel('Dataset')\n",
                "plt.title('Multi-Dataset Benchmarking: Layer Scores')\n",
                "plt.legend(['Bronze (SB)', 'Silver (SS)', 'Gold (SG)', 'FAIR-CARE'])\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 3: Regulatory Compliance\n",
                "\n",
                "Test GDPR, HIPAA, and CCPA compliance modes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run experiment (this may take ~40 minutes)\n",
                "run_experiment(\n",
                "    'experiments/scripts/runexperiment3.py',\n",
                "    [\n",
                "        '--datasets', 'compas,adult,german',\n",
                "        '--regulations', 'gdpr,hipaa,ccpa',\n",
                "        '--output', 'results/exp3.csv'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and visualize results\n",
                "exp3 = pd.read_csv('results/exp3.csv')\n",
                "exp3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot compliance by regulation\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# FAIR-CARE scores\n",
                "exp3.groupby('regulation')['faircarescore'].mean().plot(kind='bar', ax=ax1, color='steelblue')\n",
                "ax1.set_ylabel('FAIR-CARE Score')\n",
                "ax1.set_xlabel('Regulation')\n",
                "ax1.set_title('FAIR-CARE Score by Regulation')\n",
                "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=0)\n",
                "\n",
                "# Privacy risk\n",
                "exp3.groupby('regulation')['privacy_risk'].mean().plot(kind='bar', ax=ax2, color='coral')\n",
                "ax2.set_ylabel('Privacy Risk')\n",
                "ax2.set_xlabel('Regulation')\n",
                "ax2.set_title('Privacy Risk by Regulation')\n",
                "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=0)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate All Figures\n",
                "\n",
                "Create publication-ready figures for the paper."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "run_experiment(\n",
                "    'experiments/scripts/aggregateresults.py',\n",
                "    [\n",
                "        '--inputs', 'results/exp1.csv,results/exp2.csv,results/exp3.csv',\n",
                "        '--output', 'results/figures/',\n",
                "        '--format', 'png,pdf'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "All experiments complete:\n",
                "- Ablation study\n",
                "- Multi-dataset benchmarking\n",
                "- Regulatory compliance\n",
                "- Figures generated\n",
                "\n",
                "Results are ready for paper submission!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
