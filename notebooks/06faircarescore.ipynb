{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06: FAIR-CARE Score Calculation\n",
                "\n",
                "This notebook demonstrates the composite FAIR-CARE Score calculation and interpretation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "from faircare.metrics.layermetrics import BronzeMetrics, SilverMetrics, GoldMetrics\n",
                "from faircare.metrics.faircarescore import FAIRCAREScore\n",
                "import yaml\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('../configs/default.yaml', 'r') as f:\n",
                "    config = yaml.safe_load(f)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate Layer Scores\n",
                "\n",
                "Using example values from previous notebooks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bronze Score\n",
                "bronze_metrics = BronzeMetrics()\n",
                "sb = bronze_metrics.calculate({\n",
                "    'provenance_complete': True,\n",
                "    'pii_found': False,\n",
                "    'quality_score': 0.9\n",
                "})\n",
                "\n",
                "# Silver Score\n",
                "silver_metrics = SilverMetrics()\n",
                "ss = silver_metrics.calculate({\n",
                "    'utility_retention': 0.85,\n",
                "    'causal_validity': 'PASS'\n",
                "})\n",
                "\n",
                "# Gold Score\n",
                "gold_metrics = GoldMetrics()\n",
                "sg = gold_metrics.calculate({\n",
                "    'statistical_parity_difference': -0.08,\n",
                "    'utility_retention': 0.85\n",
                "})\n",
                "\n",
                "print(f\"Bronze Score (SB): {sb:.3f}\")\n",
                "print(f\"Silver Score (SS): {ss:.3f}\")\n",
                "print(f\"Gold Score (SG): {sg:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate FAIR-CARE Score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scorer = FAIRCAREScore(config)\n",
                "result = scorer.calculate(sb=sb, ss=ss, sg=sg)\n",
                "\n",
                "print(\"\\nFAIR-CARE Score Result:\")\n",
                "print(f\"  Score: {result['score']:.3f}\")\n",
                "print(f\"  Status: {result['status']}\")\n",
                "print(f\"\\nComponents:\")\n",
                "print(f\"  Bronze: {result['components']['bronze']:.3f}\")\n",
                "print(f\"  Silver: {result['components']['silver']:.3f}\")\n",
                "print(f\"  Gold: {result['components']['gold']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Layer scores\n",
                "layers = ['Bronze', 'Silver', 'Gold']\n",
                "scores = [sb, ss, sg]\n",
                "weights = [config['weights']['bronze'], config['weights']['silver'], config['weights']['gold']]\n",
                "\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Bar chart of layer scores\n",
                "colors = ['#8B4513', '#C0C0C0', '#FFD700']\n",
                "ax1.bar(layers, scores, color=colors, alpha=0.7, edgecolor='black')\n",
                "ax1.axhline(y=0.85, color='green', linestyle='--', label='EXCELLENT')\n",
                "ax1.axhline(y=0.70, color='orange', linestyle='--', label='ACCEPTABLE')\n",
                "ax1.set_ylabel('Score')\n",
                "ax1.set_title('Layer Scores')\n",
                "ax1.set_ylim(0, 1.0)\n",
                "ax1.legend()\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Pie chart of weighted contribution\n",
                "contributions = [s * w for s, w in zip(scores, weights)]\n",
                "ax2.pie(contributions, labels=layers, colors=colors, autopct='%1.1f%%', startangle=90)\n",
                "ax2.set_title(f'Weighted Contribution\\nFAIR-CARE Score: {result[\"score\"]:.3f}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sensitivity Analysis\n",
                "\n",
                "How does the FAIR-CARE Score change with different layer scores?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vary Gold score while keeping Bronze and Silver constant\n",
                "gold_range = np.linspace(0.5, 1.0, 20)\n",
                "faircare_scores = []\n",
                "\n",
                "for sg_var in gold_range:\n",
                "    result_var = scorer.calculate(sb=sb, ss=ss, sg=sg_var)\n",
                "    faircare_scores.append(result_var['score'])\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(gold_range, faircare_scores, linewidth=2, marker='o')\n",
                "plt.axhline(y=0.85, color='green', linestyle='--', alpha=0.5, label='EXCELLENT')\n",
                "plt.axhline(y=0.70, color='orange', linestyle='--', alpha=0.5, label='ACCEPTABLE')\n",
                "plt.xlabel('Gold Score (SG)')\n",
                "plt.ylabel('FAIR-CARE Score')\n",
                "plt.title('Sensitivity: FAIR-CARE Score vs Gold Score\\n(Bronze and Silver held constant)')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Interpretation Guide\n",
                "\n",
                "| Score Range | Status | Interpretation |\n",
                "|-------------|--------|----------------|\n",
                "| ≥ 0.85 | EXCELLENT | Robust ethical governance in place |\n",
                "| 0.70-0.85 | ACCEPTABLE | Governance present, improvements recommended |\n",
                "| < 0.70 | AT RISK | Significant governance gaps |\n",
                "\n",
                "**Current Status**: " + result['status'
                ] + " (" + f\"{result['score']:.3f}\" + ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "FAIR-CARE Score calculation complete:\n",
                "- ✅ Layer scores computed\n",
                "- ✅ Composite score calculated\n",
                "- ✅ Status determined\n",
                "- ✅ Visualizations created\n",
                "\n",
                "**Next**: Proceed to notebook 07 for full experiments."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}