{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05: Gold Layer - Fairness and Bias Mitigation\n",
                "\n",
                "This notebook demonstrates:\n",
                "- Bias mitigation using AIF360\n",
                "- Fairness metrics calculation\n",
                "- Before/after comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "from pyspark.sql import SparkSession\n",
                "from faircare.gold.biasmitigation import BiasMitigator\n",
                "from faircare.gold.fairnessmetrics import FairnessMetrics\n",
                "from faircare.metrics.layermetrics import GoldMetrics\n",
                "import yaml\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark = SparkSession.builder.appName(\"FAIR-CARE-Gold\").getOrCreate()\n",
                "\n",
                "with open('../configs/default.yaml', 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "dataset_config = config['datasets']['compas']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Silver Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "silver_df = spark.read.format(\"delta\").load(dataset_config['silver_path'])\n",
                "print(f\"Silver records: {silver_df.count()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fairness Metrics (Before Mitigation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fairness_calculator = FairnessMetrics(dataset_config)\n",
                "fairness_before = fairness_calculator.calculate(silver_df)\n",
                "\n",
                "print(\"\\nFairness Metrics (Before Mitigation):\")\n",
                "print(f\"  Statistical Parity Difference: {fairness_before.get('statistical_parity_difference', 'N/A')}\")\n",
                "print(f\"  Disparate Impact: {fairness_before.get('disparate_impact', 'N/A')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bias Mitigation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mitigator = BiasMitigator(dataset_config)\n",
                "gold_df = mitigator.mitigate(silver_df, spark)\n",
                "\n",
                "print(f\"\\nGold records: {gold_df.count()}\")\n",
                "if 'instance_weights' in gold_df.columns:\n",
                "    print(\"Reweighing applied successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fairness Metrics (After Mitigation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fairness_after = fairness_calculator.calculate(gold_df)\n",
                "\n",
                "print(\"\\nFairness Metrics (After Mitigation):\")\n",
                "print(f\"  Statistical Parity Difference: {fairness_after.get('statistical_parity_difference', 'N/A')}\")\n",
                "print(f\"  Disparate Impact: {fairness_after.get('disparate_impact', 'N/A')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "metrics = ['SPD', 'DI']\n",
                "before = [\n",
                "    fairness_before.get('statistical_parity_difference', 0),\n",
                "    fairness_before.get('disparate_impact', 0)\n",
                "]\n",
                "after = [\n",
                "    fairness_after.get('statistical_parity_difference', 0),\n",
                "    fairness_after.get('disparate_impact', 0)\n",
                "]\n",
                "\n",
                "x = np.arange(len(metrics))\n",
                "width = 0.35\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "ax.bar(x - width/2, before, width, label='Before Mitigation', color='coral')\n",
                "ax.bar(x + width/2, after, width, label='After Mitigation', color='lightgreen')\n",
                "\n",
                "ax.set_ylabel('Metric Value')\n",
                "ax.set_title('Fairness Metrics: Before vs After Bias Mitigation')\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels(metrics)\n",
                "ax.legend()\n",
                "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate Gold Score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gold_metrics = GoldMetrics()\n",
                "sg = gold_metrics.calculate({\n",
                "    'statistical_parity_difference': fairness_after.get('statistical_parity_difference'),\n",
                "    'utility_retention': 0.85\n",
                "})\n",
                "\n",
                "print(f\"\\nGold Score (SG): {sg:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "Gold layer complete:\n",
                "- ✅ Bias mitigated using Reweighing\n",
                "- ✅ Fairness metrics improved\n",
                "- ✅ Gold Score calculated\n",
                "\n",
                "**Next**: Proceed to notebook 06 for FAIR-CARE Score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.stop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}