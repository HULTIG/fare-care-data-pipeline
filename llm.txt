Legal Text ETL Pipeline: Implementation Guide

1. Architecture Overview
- Medallion (Bronze → Silver → Gold) with Delta Lake
- Ingestion (Spark, PySpark)
- LLM integration (Ollama, LEGAL-BERT)
- Data consumption (FastAPI, Qdrant, Superset)

2. Bronze Layer (Raw Data)
- Schema: document_id, source_url, raw_html_content, country, language, ...
- PySpark: extract, deduplicate, partition by country/language, Delta format

from pyspark.sql import SparkSession, functions as F
spark = SparkSession.builder.appName("BronzeIngestion").getOrCreate()
df_bronze = spark.read.format("jdbc").options(...).load().withColumn(...)
df_bronze.write.format("delta").mode("append").save("s3://bronze/legal_documents")

3. Silver Layer (Cleansed)
- UDF for HTML cleaning (BeautifulSoup)
- Deduplication, normalization, chunking by word count

def clean_html(html_content):
    ... # BeautifulSoup logic

df_silver = df_bronze.dropDuplicates(["data_hash"]).withColumn(...)
df_silver.write.format("delta").save("s3://silver/legal_documents")

4. Gold Layer (LLM-Enhanced)
- LLM tasks: text summary, entity extraction, topic classification (Ollama API)
- Vector: LEGAL-BERT embeddings, stored to Qdrant for RAG
- Export: Hugging Face/JSONL finetuning data

def process_with_llm(text, task):
    # Connect to Ollama, prompt: summarize, extract, classify

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('nlpaueb/legal-bert-base-uncased')
def generate_embeddings(texts):
    embeddings = model.encode(texts)
    return embeddings

5. Consumption Layer
- FastAPI for document queries
- REST endpoints for document retrieval, semantic search (via Qdrant embeddings)

from fastapi import FastAPI, Depends
app = FastAPI()
@app.get("/api/v1/documents")
async def search_documents(...):
    ...  # Query Delta Lake Gold table

6. Orchestration & Deployment
- Apache Airflow DAG (extract, transform, enhance, index)
- Docker Compose: Spark, Ollama, Qdrant, FastAPI, Superset, Airflow, Celery

7. Output for Code LLM
- instruction/completion JSONL export
df_gold.select(to_json(struct(...)).alias("json")).write.text("s3://exports/finetuning/instruction_completion.jsonl")
- QA JSONL (prompt generation)

# See PDF for all actual scripts and prompt templates